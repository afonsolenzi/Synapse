{
	"name": "D1_SQLDW_MusicService",
	"properties": {
		"folder": {
			"name": "Music Service"
		},
		"content": {
			"query": "CREATE SCHEMA musicService;\n\n-- cross engine querying is not in play on the dedicated SQL Pool\n-- note only master and the pool db are visible\nselect * from sys.databases;\n\n-- loading through COPY\n\n-- drop table musicService.UserDetails\nCREATE TABLE musicService.UserDetails\n\t(\n\t[UserID] [varchar](100) NOT NULL,\n\t[Gender] [varchar](50) NULL,\n\t[Age] [int] NULL,\n\t[Country] [varchar](50) NULL,\n\t[SignupString] [varchar](50) NULL\n\t)\nWITH\n\t(\n\tDISTRIBUTION = ROUND_ROBIN,\n\tCLUSTERED INDEX (UserID)\n\t);\nGO\n\n-- load through COPY COMMAND\nCOPY INTO musicService.UserDetails\n([UserID], [Gender], [Age], [Country], [SignupString])\nFROM 'https://warnerdatalake.dfs.core.windows.net/synapse/musicdata/UserDetails.csv'\nWITH\n(\n\tFILE_TYPE = 'CSV'\n\t,MAXERRORS = 0\n    ,FIRSTROW=2\n\t,ERRORFILE = 'https://warnerdatalake.dfs.core.windows.net/synapse/sqldw/errors/'\n\t,IDENTITY_INSERT = 'OFF'\n)OPTION (LABEL = 'Load musicService.UserDetails')\nGO\n\n-- PK or UNIQUE can be declared but are NOT ENFORCED\n-- as a matter of fact, declaring them unique when they are not can make the optimizer return bad results\n-- If you're going to declare them you have to make sure in your ETL that uniqueness is met by adding logic \n-- to verify the record is not already there.\n-- FK is not supported at all, it is up to you to enforce as well.\n\n-- drop table musicService.UserDetailsWithPK\nCREATE TABLE musicService.UserDetailsWithPK\n\t(\n\t[UserID] [varchar](100) NOT NULL PRIMARY KEY NONCLUSTERED NOT ENFORCED,\n\t[Gender] [varchar](50) NULL,\n\t[Age] [int] NULL,\n\t[Country] [varchar](50) NULL,\n\t[SignupString] [varchar](50) NULL\n\t)\nWITH\n\t(\n\tDISTRIBUTION = ROUND_ROBIN,\n\tCLUSTERED COLUMNSTORE INDEX\n\t);\n\nINSERT INTO musicService.UserDetailsWithPK([UserID],[Gender],[Age],[Country],[SignupString])\nSELECT [UserID],[Gender],[Age],[Country],[SignupString]\nFROM musicService.UserDetails;\n\nINSERT INTO musicService.UserDetailsWithPK([UserID],[Gender],[Age],[Country],[SignupString]) -- insert a duplicate\nSELECT [UserID],[Gender],[Age],[Country],[SignupString]\nFROM musicService.UserDetails\nWHERE UserID='c72565bcf001badd93b928931482e8dfc1ee700f';\n\nSELECT COUNT(*) FROM musicService.UserDetailsWithPK -- It doesn't enforce anything\nWHERE UserID='c72565bcf001badd93b928931482e8dfc1ee700f';\n\nSELECT COUNT(*),UserID FROM musicService.UserDetailsWithPK -- Uh-oh wrong result!\nWHERE UserID='c72565bcf001badd93b928931482e8dfc1ee700f'\nGROUP BY UserID;\n\n\n-- Dealing with errors during data load\n-- let's reset the table\nTRUNCATE TABLE musicService.UserDetails;\nGO\n\n-- this will fail\n-- you have to check the errorfile for details\nCOPY INTO musicService.UserDetails\n([UserID], [Gender], [Age], [Country], [SignupString])\nFROM 'https://warnerdatalake.dfs.core.windows.net/synapse/musicdata/UserDetailsWithIssues.csv'\nWITH\n(\n\tFILE_TYPE = 'CSV'\n\t,MAXERRORS = 0\n    ,FIRSTROW=2\n\t,ERRORFILE = 'https://warnerdatalake.dfs.core.windows.net/synapse/sqldw/errors/'\n\t,IDENTITY_INSERT = 'OFF'\n)OPTION (LABEL = 'Load musicService.UserDetails')\nGO\n\n-- no rows loaded at all because MAXERRORS=0 has no tolerance\nSELECT TOP 100 * FROM musicService.UserDetails\nGO\n\n-- we can increase the tolerance\nCOPY INTO musicService.UserDetails\n([UserID], [Gender], [Age], [Country], [SignupString])\nFROM 'https://warnerdatalake.dfs.core.windows.net/synapse/musicdata/UserDetailsWithIssues.csv'\nWITH\n(\n\tFILE_TYPE = 'CSV'\n\t,MAXERRORS = 0 -- change this up\n    ,FIRSTROW=2\n\t,ERRORFILE = 'https://warnerdatalake.dfs.core.windows.net/synapse/sqldw/errors/'\n\t,IDENTITY_INSERT = 'OFF'\n)OPTION (LABEL = 'Load musicService.UserDetails');\nGO\n\n-- now the non-problematic rows are there\nSELECT TOP 100 * FROM musicService.UserDetails;\nGO\n\n-- Let's load a hash distributed table: User Artist Plays\n\n-- drop table musicService.UserArtistPlays;\nCREATE TABLE musicService.UserArtistPlays\n\t(\n\t UserID varchar(100) not null,\n\t Artist varchar(100) not null,\n\t Plays int not null\n\t)\nWITH\n\t(\n\tDISTRIBUTION = HASH([Artist]), \n\t CLUSTERED COLUMNSTORE INDEX\n\t);\n\nCOPY INTO musicService.UserArtistPlays\n(UserID 1, Artist 2, Plays 3)\nFROM 'https://warnerdatalake.dfs.core.windows.net/synapse/musicdata/userartistplays.parquet'\nWITH\n(\n\tFILE_TYPE = 'PARQUET'\n\t,MAXERRORS = 0\n\t,IDENTITY_INSERT = 'OFF'\n)OPTION (LABEL = 'Load musicService.UserArtistPlays');\nGO\n\n-- no issues with the data load, table access is transparent\nSELECT count(*) FROM musicService.UserArtistPlays;\nGO\n\n\n-- loading through External Table\nCREATE DATABASE SCOPED CREDENTIAL [SynapseIdentity]\nWITH IDENTITY = 'Managed Identity';\nGO\n\n--drop external data source synapse;\nCREATE EXTERNAL DATA SOURCE synapse\nWITH (\n    TYPE = HADOOP,\n    LOCATION   = 'abfss://synapse@warnerdatalake.dfs.core.windows.net'\n)\nGO\n\nCREATE EXTERNAL FILE FORMAT CSVFileFormat \nWITH \n(   FORMAT_TYPE = DELIMITEDTEXT\n,   FORMAT_OPTIONS  (   FIELD_TERMINATOR = ','\n                    ,   STRING_DELIMITER = ''\n                    ,   DATE_FORMAT      = 'yyyy-MM-dd HH:mm:ss'\n                    ,   USE_TYPE_DEFAULT = FALSE\n                    ,   FIRST_ROW=2\n                    )\n);\nGO\n\nCREATE SCHEMA [stage];\nGO\n\nCREATE EXTERNAL TABLE [stage].ArtistRates\n(\n    [ArtistID] [int] NOT NULL,\n\t[ArtistName] varchar(100) NOT NULL,\n\t[Rate] int NULL\n)\nWITH\n(\n    LOCATION='/musicdata/ArtistRates.csv' \n,   DATA_SOURCE = synapse\n,   FILE_FORMAT = CSVFileFormat\n,   REJECT_TYPE = VALUE\n,   REJECT_VALUE = 0\n)\nGO\n\nSELECT * from [stage].ArtistRates;\n\n-- to fully materialize the data into the SQL MPP engine we CTAS the table from the External one\n\n-- drop table [musicService].[ArtistRates] \nCREATE TABLE [musicService].[ArtistRates]       \nWITH (DISTRIBUTION = REPLICATE, HEAP) \nAS \nSELECT * FROM [stage].[ArtistRates]         \nOPTION (LABEL = 'Load ArtistRates');\n\n-- no issues\nSELECT * from [musicService].ArtistRates;\n\n-- THE GUI ALSO OFFERS WAYS TO LOAD DATA!\n\n-- check distribution type\nSELECT t.name, td.distribution_policy_desc \nFROM sys.tables t INNER JOIN \nsys.pdw_table_distribution_properties td ON t.object_id=td.object_id;\n\n-- if it's hashed, what's the key?\n-- replace with the table name in the WHERE clause\nSELECT t.name, cols.name, st.name [type_name]\nFROM sys.tables t INNER JOIN\nsys.columns cols ON t.object_id=cols.object_id \nINNER JOIN sys.pdw_column_distribution_properties colp ON cols.object_id=colp.object_id AND cols.column_id=colp.column_id\nINNER JOIN sys.types st ON cols.system_type_id=st.system_type_id\nWHERE t.name='UserArtistPlays' AND colp.distribution_ordinal=1;\n\n-- check distributions\nDBCC PDW_SHOWSPACEUSED('musicService.ArtistRates'); -- REPLICATED\nDBCC PDW_SHOWSPACEUSED('musicService.UserDetails'); -- ROUND ROBIN\nDBCC PDW_SHOWSPACEUSED('musicService.UserArtistPlays'); -- HASHED on Artist\n\n-- analyzing the HASHED table in detail\nSELECT t.name,nps.[row_count],nps.[used_page_count]*8.0/1024 as usedSpaceMB, nt.distribution_id\n FROM\n   sys.tables t\nINNER JOIN sys.indexes i\n    ON  t.[object_id] = i.[object_id]\n    AND i.[index_id] <= 1 /* HEAP = 0, CLUSTERED or CLUSTERED_COLUMNSTORE =1 */\nINNER JOIN sys.pdw_table_mappings tm\n    ON t.[object_id] = tm.[object_id]\nINNER JOIN sys.pdw_nodes_tables nt\n    ON tm.[physical_name] = nt.[name]\nINNER JOIN sys.dm_pdw_nodes_db_partition_stats nps\n    ON nt.[object_id] = nps.[object_id]\n    AND nt.[pdw_node_id] = nps.[pdw_node_id]\n    AND nt.[distribution_id] = nps.[distribution_id]\nWHERE t.name='UserArtistPlays'\nORDER BY usedSpaceMB DESC;\n\n-- you should keep track of open rowgroups as well\n-- same concept applies as to columnstores in SQL Server\nwith cte\nas\n(\nselect   tb.[name]                    AS [logical_table_name]\n,        rg.[row_group_id]            AS [row_group_id]\n,        rg.[state]                   AS [state]\n,        rg.[state_desc]              AS [state_desc]\n,        rg.[total_rows]              AS [total_rows]\n,        rg.[trim_reason_desc]        AS trim_reason_desc\n,        mp.[physical_name]           AS physical_name\nFROM    sys.[schemas] sm\nJOIN    sys.[tables] tb               ON  sm.[schema_id]          = tb.[schema_id]\nJOIN    sys.[pdw_table_mappings] mp   ON  tb.[object_id]          = mp.[object_id]\nJOIN    sys.[pdw_nodes_tables] nt     ON  nt.[name]               = mp.[physical_name]\nJOIN    sys.[dm_pdw_nodes_db_column_store_row_group_physical_stats] rg      \nON  rg.[object_id]     = nt.[object_id]\nAND rg.[pdw_node_id]   = nt.[pdw_node_id]\nAND rg.[distribution_id]    = nt.[distribution_id]\n)\nselect *\nfrom cte\nwhere logical_table_name = 'UserArtistPlays';\n\n-- you can compress and close all rowgroups by rebuilding the index\nALTER INDEX ALL ON [musicService].[UserArtistPlays] REORGANIZE; -- this compresses closed groups in an ONLINE operation\nALTER INDEX ALL ON [musicService].[UserArtistPlays] REBUILD; -- this closes all groups and compresses them in an OFFLINE operation\n\n-- what about IDENTITY / SEQUENCE\n-- Identities have hops, there are no sequences\n\n--DROP TABLE musicService.UserDetailsWithIdentity;\nCREATE TABLE musicService.UserDetailsWithIdentity\n\t(\n\t[UserDetailsID] [bigint] IDENTITY(1,1),\n\t[UserID] [varchar](100) NOT NULL,\n\t[Gender] [varchar](50) NULL,\n\t[Age] [int] NULL,\n\t[Country] [varchar](50) NULL,\n\t[SignupString] [varchar](50) NULL\n\t)\nWITH\n\t(\n\tDISTRIBUTION = ROUND_ROBIN,\n\tCLUSTERED COLUMNSTORE INDEX\n\t);\n\nINSERT INTO musicService.UserDetailsWithIdentity([UserID],[Gender],[Age],[Country],[SignupString])\nSELECT TOP 100 [UserID],[Gender],[Age],[Country],[SignupString]\nFROM musicService.UserDetails;\n\nSELECT UserDetailsID, UserID from musicService.UserDetailsWithIdentity\norder by UserDetailsID ASC; -- recommend to use BIGINT!\n\n\n-- what about Partitioning?\n-- Partitioning works but it can lead to very thin columnstore segments (not a lot of rows)\n-- Only use if you have tables that will actually fill up the partitions\n-- For example, 60 distributions x 52 partitions (1 year weekly) = 3120 partitions total\n-- Assuming the optimal columnstore segment should have 1M rows then that is 3 120 000 000 records\n\n-- convert to a proper date column\n-- DROP TABLE musicService.UserDetailsConverted;\nCREATE TABLE musicService.UserDetailsConverted\n\t(\n\t[UserID],\n\t[Gender],\n\t[Age],\n\t[Country],\n\t[SignupDate]\n\t)\nWITH\n\t(\n\tDISTRIBUTION = ROUND_ROBIN\n\t)\nAS\nSELECT[UserID],[Gender],[Age],[Country],convert(date,[SignupString],107) SignupDate\nFROM musicService.UserDetails;\n\nSELECT min(SignupDate) minDate, max(SignupDate) maxDate\nFROM musicService.UserDetailsConverted;\n\n-- now adding partitioning\n\n-- DROP TABLE musicService.UserDetailsPartitioned;\nCREATE TABLE musicService.UserDetailsPartitioned\nWITH\n\t(\n\tDISTRIBUTION = ROUND_ROBIN,\n\tCLUSTERED COLUMNSTORE INDEX,\n\tPARTITION\n    (\n        SignupDate RANGE RIGHT FOR VALUES\n        (\n        '2007-01-01','2008-01-01','2009-01-01','2010-01-01','2011-01-01','2012-01-01','2013-01-01','2014-01-01','2015-01-01'\n        )\n    )\n)\nAS\nSELECT[UserID],[Gender],[Age],[Country],[SignupDate]\nFROM musicService.UserDetailsConverted;\n\n-- get the space per partition, notice how most partitions are very empty\n-- before implementing partitioning make sure you have enough data to fill these partitions up!\nSELECT pnp.partition_number,t.name,nps.[row_count],nps.[used_page_count]*8.0/1024 as usedSpaceMB,nt.distribution_id\n FROM\n   sys.tables t\nINNER JOIN sys.indexes i\n    ON  t.[object_id] = i.[object_id]\n    AND i.[index_id] <= 1 /* HEAP = 0, CLUSTERED or CLUSTERED_COLUMNSTORE =1 */\nINNER JOIN sys.pdw_table_mappings tm\n    ON t.[object_id] = tm.[object_id]\nINNER JOIN sys.pdw_nodes_tables nt\n    ON tm.[physical_name] = nt.[name]\nINNER JOIN sys.pdw_nodes_partitions pnp \n    ON nt.[object_id]=pnp.[object_id] \n\tAND nt.[pdw_node_id]=pnp.[pdw_node_id] \n\tAND nt.[distribution_id] = pnp.[distribution_id]\nINNER JOIN sys.dm_pdw_nodes_db_partition_stats nps\n    ON nt.[object_id] = nps.[object_id]\n    AND nt.[pdw_node_id] = nps.[pdw_node_id]\n    AND nt.[distribution_id] = nps.[distribution_id]\n\tAND pnp.[partition_id]=nps.[partition_id]\nWHERE t.name='UserDetailsPartitioned'\nORDER BY usedSpaceMB DESC;\n\n\n-- Analyze the data warehouse operations at different levels\n-- at the request level\nSELECT *\nFROM sys.dm_pdw_exec_requests r \nWHERE r.[label] = 'Load musicService.UserArtistPlays'\norder by r.start_time desc;\n\n-- at the worker level\nSELECT w.*\nFROM sys.dm_pdw_exec_requests r \nJOIN sys.dm_pdw_dms_workers w on r.request_id = w.request_id\nWHERE r.[label] = 'Load musicService.UserArtistPlays'\norder by w.start_time asc, step_index asc;\n\n-- at the distribution level\nSELECT req.* \nFROM sys.dm_pdw_exec_requests r \nJOIN sys.dm_pdw_sql_requests req on r.request_id = req.request_id\nWHERE r.[label] = 'Load musicService.UserArtistPlays'\norder by req.step_index,req.distribution_id\n\n\n-- same thing for a SELECT query\n\n-- report across all users and artists\nSELECT TOP 10 ua.Artist, Rate, SUM(Plays) AllPlays,[Age]\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlays ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetails ud ON ua.UserID=ud.[UserID]\nWHERE ud.Age BETWEEN 30 and 40 \nGROUP BY ua.Artist,ar.Rate,ud.Age\nORDER BY AllPlays DESC\nOPTION(LABEL='Top Artists for Users 30-40');\n\n-- get the estimated plan\n-- SSMS provides a GUI based one\nEXPLAIN\nSELECT TOP 10 ua.Artist, Rate, SUM(Plays) AllPlays,[Age]\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlays ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetails ud ON ua.UserID=ud.[UserID]\nWHERE ud.Age BETWEEN 30 and 40 \nGROUP BY ua.Artist,ar.Rate,ud.Age\nORDER BY AllPlays DESC\nOPTION(LABEL='Top Artists for Users 30-40');\n\n-- 2 shuffle operations, we could redefine the distribution\n-- UserDetails from round robin to Hash UserID\n-- UserArtistPlays from Hash Artist to Hash UserID\n-- If we hash both tables on the same UserID column then all the data for \n-- a single user is colocated in the same distribution and the join can be done with no shuffling!\n\n-- DROP TABLE musicService.UserArtistPlaysHashedUser;\nCREATE TABLE musicService.UserArtistPlaysHashedUser\nWITH\n\t(\n\tDISTRIBUTION = HASH([UserID])\n\t)\nAS\nSELECT * FROM musicService.UserArtistPlays;\n\n\n-- DROP TABLE musicService.UserDetailsHashedUser;\nCREATE TABLE musicService.UserDetailsHashedUser\nWITH\n\t(\n\tDISTRIBUTION = HASH([UserID])\n\t)\nAS\nSELECT * FROM musicService.UserDetails;\n\n-- target these new tables for the same query\nSELECT TOP 10 ua.Artist, Rate, SUM(Plays) AllPlays,[Age]\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlaysHashedUser ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetailsHashedUser ud ON ua.UserID=ud.[UserID]\nWHERE ud.Age BETWEEN 30 and 40 \nGROUP BY ua.Artist,ar.Rate,ud.Age\nORDER BY AllPlays DESC\nOPTION(LABEL='Top Artists for Users 30-40 - Hashed by User');\n\n\n\n\n-- Let's run some queries to track their steps\n-- report for one artist\nSELECT TOP 10 ua.Artist, Rate, SUM(Plays) AllPlays,[Age]\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlays ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetails ud ON ua.UserID=ud.[UserID]\nWHERE ud.Age BETWEEN 20 and 40 AND Artist='Muse'\nGROUP BY ua.Artist,ar.Rate,ud.Age\nORDER BY AllPlays DESC\nOPTION(LABEL='Top Age Ranges for Muse between 20-40');\n\n-- individual request steps\nSELECT Step_index,Command,Operation_type,Distribution_type,Location_type,total_elapsed_time,Row_count,Estimated_rows\nfrom sys.dm_pdw_request_steps \nWHERE request_id = (SELECT request_id\n\t\t\t\t\t\tFROM  sys.dm_pdw_exec_requests\n\t\t\t\t\t\tWHERE [label] = 'Top Age Ranges for Muse between 20-40');\n\n-- detailed steps info\nselect distinct \n\t\tper.request_id, \n\t\tper.session_id, \n\t\tper.[status], \n\t\tper.start_time, \n\t\tper.end_time, \n\t\tper.total_elapsed_time, \n\t\tper.error_id, \n\t\tper.database_id, \n\t\tper.command, \n\t\tper.resource_class, \n\t\tprs.step_index, \n\t\tprs.operation_type, \n\t\tprs.distribution_type, \n\t\tprs.location_type, \n\t\tprs.[status] as Step_Status, \n\t\tprs.error_id as step_error_id, \n\t\tprs.start_time as Step_start_time, \n\t\tprs.end_time as step_end_time, \n\t\tprs.total_elapsed_time as step_total_elapsed_time, \n\t\tprs.row_count, \n\t\tprs.command as step_command, \n\t\tpdw.dms_step_index, \n\t\tn.[type] + '/' + n.[name] AS [node], \n\t\tpdw.distribution_id,\n\t\tpdw.[type], \n\t\tpdw.[status] as DMS_Status, \n\t\tpdw.bytes_per_sec, \n\t\tpdw.Bytes_processed, \n\t\tpdw.rows_processed, \n\t\tpdw.start_time as DMS_Start_Time,\n\t\tpdw.end_time as DMS_End_Time, \n\t\tpdw.total_elapsed_time as DMS_Total_Elapsed_Time\n FROM \n\tsys.dm_pdw_exec_requests per\n\t\tINNER JOIN sys.dm_pdw_request_steps prs\n\t \t\tON per.request_id = prs.request_id\n\t\tLEFT OUTER JOIN sys.dm_pdw_dms_workers pdw \n\t\t\tON prs.request_id = pdw.request_id \n\t\t\tand prs.step_index = pdw.step_index \n\t\tLEFT OUTER JOIN sys.dm_pdw_nodes n\n\t\t\tON pdw.pdw_node_id = n.pdw_node_id\nWHERE pdw.Step_index is not null\n AND  per.[label] = 'Top Age Ranges for Muse between 20-40'\n\n\n-- is there a particular skew?\nSELECT r.[command],steps.[step_index],steps.[operation_type],steps.[distribution_type],steps.[location_type],\nsteps.[total_elapsed_time], steps.[command] step_command,\nmax(sql_reqs.[total_elapsed_time]) maxPerDistributionTime,\nmin(sql_reqs.[total_elapsed_time]) minPerDistributionTime,\navg(sql_reqs.[total_elapsed_time]) avgPerDistributionTime,\nstdev(sql_reqs.[total_elapsed_time]) stdDeviationDistributionTime\nFROM sys.dm_pdw_exec_requests r\nINNER JOIN sys.dm_pdw_request_steps steps\nON r.[request_id]=steps.[request_id]\nLEFT JOIN sys.dm_pdw_sql_requests sql_reqs\nON steps.[request_id]=sql_reqs.[request_id] AND steps.[step_index]=sql_reqs.[step_index]\nWHERE r.[label]='Top Age Ranges for Muse between 20-40'\nGROUP BY r.[command],steps.[step_index],steps.[operation_type],steps.[distribution_type],steps.[location_type],\nsteps.[total_elapsed_time], steps.[command] \nORDER BY steps.[step_index];\n\n\n-- are stats out of date?\nselect \nobjIdsWithStats.[object_id], \nactualRowCounts.[schema], \nactualRowCounts.logical_table_name, \nstatsRowCounts.stats_row_count, \nactualRowCounts.actual_row_count,\nrow_count_difference = CASE\n\tWHEN actualRowCounts.actual_row_count >= statsRowCounts.stats_row_count THEN actualRowCounts.actual_row_count - statsRowCounts.stats_row_count\n\tELSE statsRowCounts.stats_row_count - actualRowCounts.actual_row_count\nEND,\npercent_deviation_from_actual = CASE\n\tWHEN actualRowCounts.actual_row_count = 0 THEN statsRowCounts.stats_row_count\n\tWHEN statsRowCounts.stats_row_count = 0 THEN actualRowCounts.actual_row_count\n\tWHEN actualRowCounts.actual_row_count >= statsRowCounts.stats_row_count THEN CONVERT(NUMERIC(18, 0), CONVERT(NUMERIC(18, 2), (actualRowCounts.actual_row_count - statsRowCounts.stats_row_count)) / CONVERT(NUMERIC(18, 2), actualRowCounts.actual_row_count) * 100)\n\tELSE CONVERT(NUMERIC(18, 0), CONVERT(NUMERIC(18, 2), (statsRowCounts.stats_row_count - actualRowCounts.actual_row_count)) / CONVERT(NUMERIC(18, 2), actualRowCounts.actual_row_count) * 100)\nEND\nfrom\n(\n\tselect distinct object_id from sys.stats where stats_id > 1\n) objIdsWithStats\nleft join\n(\n\tselect object_id, sum(rows) as stats_row_count from sys.partitions group by object_id\n) statsRowCounts\non objIdsWithStats.object_id = statsRowCounts.object_id \nleft join\n(\n\tSELECT sm.name [schema] ,\n\ttb.name logical_table_name ,\n\ttb.object_id object_id ,\n\tSUM(rg.row_count) actual_row_count\n\tFROM sys.schemas sm\n\tINNER JOIN sys.tables tb ON sm.schema_id = tb.schema_id\n\tINNER JOIN sys.pdw_table_mappings mp ON tb.object_id = mp.object_id\n\tINNER JOIN sys.pdw_nodes_tables nt ON nt.name = mp.physical_name\n\tINNER JOIN sys.dm_pdw_nodes_db_partition_stats rg\n\tON rg.object_id = nt.object_id\n\tAND rg.pdw_node_id = nt.pdw_node_id\n\tAND rg.distribution_id = nt.distribution_id\n\tGROUP BY sm.name, tb.name, tb.object_id\n) actualRowCounts\non objIdsWithStats.object_id = actualRowCounts.object_id;\n\n-- Updating stats\nUPDATE STATISTICS musicService.UserDetailsWithPK;\n\n-- when were the stats last updated?\nSELECT\n    sm.[name] AS [schema_name],\n    tb.[name] AS [table_name],\n    co.[name] AS [stats_column_name],\n    st.[name] AS [stats_name],\n    STATS_DATE(st.[object_id],st.[stats_id]) AS [stats_last_updated_date]\nFROM\n    sys.objects ob\n    JOIN sys.stats st\n        ON  ob.[object_id] = st.[object_id]\n    JOIN sys.stats_columns sc\n        ON  st.[stats_id] = sc.[stats_id]\n        AND st.[object_id] = sc.[object_id]\n    JOIN sys.columns co\n        ON  sc.[column_id] = co.[column_id]\n        AND sc.[object_id] = co.[object_id]\n    JOIN sys.types  ty\n        ON  co.[user_type_id] = ty.[user_type_id]\n    JOIN sys.tables tb\n        ON  co.[object_id] = tb.[object_id]\n    JOIN sys.schemas sm\n        ON  tb.[schema_id] = sm.[schema_id]\nWHERE st.Auto_created=1 or st.User_created=1;\n\n-- stats of a table\nSELECT *\nFROM sys.stats\n\tWHERE object_id = OBJECT_ID('musicService.UserDetails');\n\n-- you can still see the statistics created same as SQL Server\nDBCC SHOW_STATISTICS ('musicService.UserDetails','_WA_Sys_00000001_7775B2CE');\n\n-- there are some stats created with the table but they are empty\nDBCC SHOW_STATISTICS ('musicService.UserDetails','ClusteredIndex_bd0fab94a6ae408690be326fdb82eac6');\n\n\n-- Materialized views can enable different table distributions\n\n-- DROP VIEW musicService.mvw_artistRankingByPlays;\nCREATE MATERIALIZED VIEW musicService.mvw_artistRankingByPlays WITH( DISTRIBUTION = hash(Artist) ) \nAS \nSELECT ua.Artist, Rate, SUM(Plays) AllPlays,[Age]\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlays ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetails ud ON ua.UserID=ud.[UserID]\nGROUP BY ua.Artist,ar.Rate,ud.Age;\n\n-- direct usage (SSMS to see exec plan)\nSELECT TOP 100 Artist, sum(AllPlays) AllPlays\nFROM musicService.mvw_artistRankingByPlays\nWHERE Age BETWEEN 30 and 40 \nGROUP BY Artist, Age\nORDER BY AllPlays DESC\nOPTION(LABEL='View: Top Artists for Users 30-40');\n\n-- automatic usage\nSELECT TOP 10 Artist, Rate, SUM(Plays) AllPlays,[Age]\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlays ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetails ud ON ua.UserID=ud.[UserID]\nWHERE ud.Age BETWEEN 30 and 40 \nGROUP BY ua.Artist,ar.Rate,ud.Age\nORDER BY AllPlays DESC\nOPTION(LABEL='AutoSubstituted - Top Artists for Users 30-40');\n\n\n-- Temporary tables are batch scoped\nCREATE TABLE #tempDemo\nWITH\n\t(\n\tDISTRIBUTION = HASH([UserID]), HEAP\n\t)\nAS\n(SELECT top 100 * FROM musicService.UserArtistPlays); \n\nSELECT * FROM tempdb..#tempDemo;\nGO\n\n-- SQL DW also has a results cache\n--  maximum size of result set cache is 1 TB\n\n-- see if cache is ON/OFF\nSELECT name, is_result_set_caching_on\nFROM sys.databases;\n\n-- run from master\nuse master; -- note this won't work, a new connection is needed but the GUI does it\nGO\n\nALTER DATABASE SQLDW\nSET RESULT_SET_CACHING ON;\n\n-- switch back to SQLDW\n\n-- this is a deterministic query so it should cache\nSELECT TOP 10 ua.Artist, Rate, SUM(Plays) AllPlays,[Age]\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlays ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetails ud ON ua.UserID=ud.[UserID]\nWHERE ud.Age BETWEEN 20 and 40 AND Artist='Adele'\nGROUP BY ua.Artist,ar.Rate,ud.Age\nORDER BY AllPlays DESC\nOPTION(LABEL='Top Age Ranges for Adele between 20-40 - Deterministic');\n\n\nSELECT request_id, command, result_cache_hit,Total_elapsed_time FROM sys.dm_pdw_exec_requests\nWHERE [label] = 'Top Age Ranges for Adele between 20-40 - Deterministic';\n-- run it again!\n\n\n-- getdate() makes it un-cacheable\nSELECT TOP 10 ua.Artist, Rate, SUM(Plays) AllPlays,[Age],getdate()\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlays ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetails ud ON ua.UserID=ud.[UserID]\nWHERE ud.Age BETWEEN 20 and 40 AND Artist='Adele'\nGROUP BY ua.Artist,ar.Rate,ud.Age\nORDER BY AllPlays DESC\nOPTION(LABEL='Top Age Ranges for Adele between 20-40 - NonDeterministic');\n\nSELECT request_id, command, result_cache_hit,Total_elapsed_time FROM sys.dm_pdw_exec_requests\nWHERE [label] = 'Top Age Ranges for Adele between 20-40 - NonDeterministic';\n\n-- intentionally not cache this session (not currently working)\nSET RESULT_SET_CACHING ON;\nSET RESULT_SET_CACHING OFF;\n\n-- no field to indicate what the status is for any session though...\nselect * from sys.dm_pdw_exec_sessions\n\nSELECT TOP 15 ua.Artist, Rate, SUM(Plays) AllPlays,[Age]\nFROM musicService.ArtistRates ar JOIN musicService.UserArtistPlays ua ON ar.ArtistName = ua.Artist\nJOIN musicService.UserDetails ud ON ua.UserID=ud.[UserID]\nWHERE ud.Age BETWEEN 20 and 40 AND Artist='Adele'\nGROUP BY ua.Artist,ar.Rate,ud.Age\nORDER BY AllPlays DESC\nOPTION(LABEL='Top Age Ranges for Adele between 20-40 - Dont Cache');\n\n\nSELECT request_id, command, result_cache_hit,Total_elapsed_time FROM sys.dm_pdw_exec_requests\nWHERE [label] = 'Top Age Ranges for Adele between 20-40 - Dont Cache';\n\n-- check and cleanup\nDBCC SHOWRESULTCACHESPACEUSED; -- numbers are in KB\nDBCC DROPRESULTSETCACHE;\n\n-- turn it off (use master)\nALTER DATABASE SQLDW\nSET RESULT_SET_CACHING OFF;\n",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"poolName": "SQLDW",
				"databaseName": "SQLDW"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}